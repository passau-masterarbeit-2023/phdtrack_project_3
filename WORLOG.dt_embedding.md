# Worklog: Data structure embedding

## Objectives

### Create DTN embedding based on the graph

> Create a new embedding focused on datastructure embedding.

Create an embedding focused on encapsulating the data structures. What we want is to vectorize the data structure in a syntetic way.

Below are our stating ideas for semantic data structure embedding:

* [X] Use the number of bytes (upper bound)
* [X] Nb of pointers inside
* [X] Add addresses of DTN
* [X] Nb of ancestor and children DNT and VN, recursively with a hyperparameter being the depth (probably between 4 and 8)

### Create a KMean clustering over the data structure graph embedding

Load data generated by the Rust `semantic-embedding-dtn` into a new pipeline and perform some clustering technique so as to regroup similar structures accross files.

* [X] add the file path as a new feature so as to identify each structure with it's origin file (maybe we will discover some variations accross different versions of OpenSSH)
* [ ] create new loading data pipeline to load those data structure sample
* [ ] create a pipeline for clustering data structures (from different files) using KMean or other similar clustering algorithm.
* [ ] final objective: validate or not the **consistent KG modeling hypothesis**.

### Create a Data Structure embedding based on word2vec or other ML embedding technique

* [ ] create a new program using PyTorch with custom tokenizer and Transformer. Michaele adviced to look at Word2Vec and the gensym library.

> Word2Vec for us: learn a probability distribution that, given a sequence of last bytes of a sequence, is able to predict the the bytes, similar to what is done by NLP models.

* [ ] objective: get a consistent embedding on the data of data structure
* [ ] We can generate sample vectors and try to reuse our previous pipeline for clustering so as to verify the **consistent embedding hypothesis** on this new embedding.

## Work

### 02/06

Create pipeline to generate data to vectorize data structure : csv with each line is a datastructure. The data are :

* file
* address
* size
* nb_pointer
* for each block of 8 bytes inside the dts :
  * if it is a pointer, left empty (or no, if parameter no-pointer set)
  * else the block (hexa)

WARN : to determinate the pointer, use the range of the heap block ? yes : avoid over interpretate the data (ML)

NOTE : for 16, 32 and 64 bytes keys the number of dtn is 1038 or 1039 per files

### 01/06

Add pipeline for semantics embedding of dtns. Update CLI arg to match the new pipeline and output folder. Added some comments on code.
