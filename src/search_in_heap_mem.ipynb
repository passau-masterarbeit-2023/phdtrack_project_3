{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for elements and addresses in heap dump mem files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from dataclasses import dataclass\n",
    "from graphviz import Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program paths are OK.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@dataclass\n",
    "class ProgramParams:\n",
    "    \"\"\"\n",
    "    Wrapper class for program parameters.\n",
    "    \"\"\"\n",
    "    XXD_LINE_BLOCK_BYTE_SIZE = 16\n",
    "    POINTER_BYTE_SIZE = 8 # 64-bit, ex: C0 03 7B 09 2A 56 00 00\n",
    "\n",
    "    TEST_JSON_TEST_FILE_PATH = os.environ['HOME'] + \"/Documents/code/phdtrack/phdtrack_project_3/data/302-1644391327.json\"\n",
    "    TEST_HEAP_DUMP_RAW_FILE_PATH = os.environ['HOME'] + \"/Documents/code/phdtrack/phdtrack_project_3/data/302-1644391327-heap.raw\"\n",
    "    TEST_DATA_DIR = os.environ['HOME'] + \"/Documents/code/phdtrack/phdtrack_project_3/data/graphs\"\n",
    "    TEST_GRAPH_DATA_FILENAME = \"graph_302-1644391327.gv\"\n",
    "\n",
    "    DATA_DIR_PATH = os.environ['HOME'] + \"/Documents/code/phdtrack/phdtrack_data/Training/Training/scp/V_7_8_P1/16\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        if (\n",
    "            self.check_path_exists(self.TEST_JSON_TEST_FILE_PATH) and\n",
    "            self.check_path_exists(self.TEST_HEAP_DUMP_RAW_FILE_PATH) and\n",
    "            self.check_path_exists(self.TEST_DATA_DIR) and\n",
    "            self.check_path_exists(self.DATA_DIR_PATH)\n",
    "        ):\n",
    "            print(\"Program paths are OK.\")\n",
    "        else:\n",
    "            print(\"Program paths are NOT OK.\")\n",
    "            exit(1)\n",
    "    \n",
    "    def check_path_exists(self, path: str):\n",
    "        \"\"\"\n",
    "        Check if the path exists. Return True if it exists, False otherwise.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(path):\n",
    "            print('WARNING: Path does not exist: %s' % path)\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "PARAMS = ProgramParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of keys: 6\n"
     ]
    }
   ],
   "source": [
    "# read the JSON file and get all pair of addresses and keys\n",
    "@dataclass\n",
    "class KeyData:\n",
    "    \"\"\"\n",
    "    Wrapper class for key data.\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    key: bytes\n",
    "    addr: bytes\n",
    "    len: int\n",
    "    real_len: int\n",
    "\n",
    "heap_start_addr = None\n",
    "addr_key_pairs: dict[int, KeyData] = {} # key addr (int in base 16 - hex) -> key data (KeyData)\n",
    "\n",
    "with open(PARAMS.TEST_JSON_TEST_FILE_PATH, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "    heap_start_addr = bytes.fromhex(json_data[\"HEAP_START\"])\n",
    "    \n",
    "    for json_key_name in json_data:\n",
    "        # match json key names that start with 'KEY_' and are followed by a single letter\n",
    "        if json_key_name.startswith('KEY_') and len(json_key_name) == 5:\n",
    "            real_key_addr = bytes.fromhex(json_data[json_key_name + \"_ADDR\"])\n",
    "            addr_key_pairs[int.from_bytes(real_key_addr, byteorder='big', signed=False)] = KeyData(\n",
    "                name=json_key_name,\n",
    "                key=bytes.fromhex(json_data[json_key_name]),\n",
    "                addr=real_key_addr,\n",
    "                len=int(json_data[json_key_name + \"_LEN\"]),\n",
    "                real_len=int(json_data[json_key_name + \"_REAL_LEN\"])\n",
    "            )\n",
    "            # print(\n",
    "            #     'addr: ', hex(int.from_bytes(real_key_addr, byteorder='big', signed=False)), \n",
    "            #     'real key addr: ', json_data[json_key_name + \"_ADDR\"]\n",
    "            # )\n",
    "\n",
    "# print nb of keys\n",
    "print(\"Nb of keys: %d\" % len(addr_key_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000000005102000000000000\n",
      "02040706070704070504070204060106\n",
      "06070107060702020201000000000001\n",
      "03010001000000000000000000000001\n",
      "00000000030200000000000000000000\n",
      "Number of dump lines: 17408 of size: 16 bytes\n",
      "key name: KEY_A index: 5537 index in hex: 0x15a1\n",
      "Key found: KEY_A\n",
      "key name: KEY_B index: 4533 index in hex: 0x11b5\n",
      "Key found: KEY_B\n",
      "key name: KEY_C index: 5546 index in hex: 0x15aa\n",
      "Key found: KEY_C\n",
      "key name: KEY_D index: 4537 index in hex: 0x11b9\n",
      "Key found: KEY_D\n",
      "key name: KEY_E index: 6069 index in hex: 0x17b5\n",
      "Key found: KEY_E\n",
      "key name: KEY_F index: 3620 index in hex: 0xe24\n",
      "Key found: KEY_F\n"
     ]
    }
   ],
   "source": [
    "# read the heap dump file and search for the keys\n",
    "with open(PARAMS.TEST_HEAP_DUMP_RAW_FILE_PATH, 'rb') as f:\n",
    "    heap_dump = f.read()\n",
    "\n",
    "    # split the heap dump into lines of 16 bytes\n",
    "    heap_dump_lines = [heap_dump[i:i+PARAMS.XXD_LINE_BLOCK_BYTE_SIZE] for i in range(0, len(heap_dump), PARAMS.XXD_LINE_BLOCK_BYTE_SIZE)]\n",
    "    \n",
    "    # print first 5 lines\n",
    "    for i in range(5):\n",
    "        print(heap_dump_lines[i].hex())\n",
    "    \n",
    "    print(\"Number of dump lines: %d\" % len(heap_dump_lines), \"of size:\", PARAMS.XXD_LINE_BLOCK_BYTE_SIZE, \"bytes\")\n",
    "\n",
    "    # go to known key addresses and check if the key is there\n",
    "    for key_addr in addr_key_pairs:\n",
    "        key_data = addr_key_pairs[key_addr]\n",
    "\n",
    "        # get the line index of the key address\n",
    "        # WARN: Need to divide the line index by 16 because the heap dump is in bytes\n",
    "        # and line addresses is the address of the first byte of the line.\n",
    "        # so each line address is 16 bytes apart.\n",
    "        line_index = (int.from_bytes(key_data.addr, byteorder='big', signed=False) - int.from_bytes(heap_start_addr, byteorder='big', signed=False)) // PARAMS.XXD_LINE_BLOCK_BYTE_SIZE\n",
    "        print(\"key name:\", key_data.name, \"index:\", line_index, \"index in hex:\", hex(line_index))\n",
    "        if (heap_dump_lines[line_index] == key_data.key):\n",
    "            print(\"Key found: %s\" % key_data.name)\n",
    "        else:\n",
    "            print(\"Key NOT found: %s\" % key_data.name)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow the pointers and build the graphs\n",
    "def follow_pointers_and_build_graph(\n",
    "    raw_heap_dump_file_path: str, \n",
    "    pointer_byte_size=PARAMS.POINTER_BYTE_SIZE,\n",
    "    debug=False\n",
    "):\n",
    "    with open(raw_heap_dump_file_path, 'rb') as f:\n",
    "        heap_dump = f.read()\n",
    "\n",
    "        # split the heap dump into lines of POINTER_BYTE_SIZE bytes\n",
    "        heap_dump_lines = [heap_dump[i:i+pointer_byte_size] for i in range(0, len(heap_dump), pointer_byte_size)]\n",
    "        \n",
    "        # print some lines\n",
    "        if debug: \n",
    "            for i in range(100, 105):\n",
    "                print(heap_dump_lines[i].hex(), \"int:\", int.from_bytes(heap_dump_lines[i], byteorder='big', signed=False))\n",
    "        \n",
    "            print(\"Number of dump lines: %d\" % len(heap_dump_lines), \"of size:\", pointer_byte_size, \"bytes\")\n",
    "        \n",
    "        graph_file_as_string = \"\"\n",
    "        graph_file_as_string += \"digraph %s {\\n\" % str(os.path.basename(raw_heap_dump_file_path)).replace(\".raw\", \"\")\n",
    "\n",
    "        # get HEAP_START from the JSON file\n",
    "        heap_start_addr = None\n",
    "        with open(raw_heap_dump_file_path.replace(\"-heap.raw\", \".json\"), 'r') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            heap_start_addr = bytes.fromhex(json_data[\"HEAP_START\"])\n",
    "        assert heap_start_addr is not None\n",
    "\n",
    "        # get the min and max address of the heap\n",
    "        min_addr = int.from_bytes(heap_start_addr, byteorder='big', signed=False) # HEAP_START\n",
    "        max_addr = min_addr + len(heap_dump_lines) * pointer_byte_size\n",
    "\n",
    "        if debug:\n",
    "            print(\"min_addr: %d, max_addr: %d\" % (min_addr, max_addr))\n",
    "            print(\"hex min_addr: %s, hex max_addr: %s\" % (hex(min_addr), hex(max_addr)))\n",
    "\n",
    "        # go through all the potential pointers in the heap dump\n",
    "        counter = 0\n",
    "        for i, potential_ptr in enumerate(heap_dump_lines):\n",
    "            potential_ptr_int = int.from_bytes(potential_ptr, byteorder='big', signed=False)\n",
    "            if potential_ptr_int <= max_addr and potential_ptr_int > 0 and potential_ptr_int % 16 == 0 and potential_ptr_int >= min_addr:\n",
    "                print(\"found potential_ptr_int: %d, hex potential_ptr_int: %s\" % (potential_ptr_int, hex(potential_ptr_int)))\n",
    "\n",
    "            # check is the potential pointer is in range of the heap\n",
    "            if potential_ptr_int >= min_addr and potential_ptr_int <= max_addr:\n",
    "                current_ptr_addr = i * pointer_byte_size + min_addr\n",
    "\n",
    "                # write the pointer to the graph file\n",
    "                graph_file_as_string += \"    {} -> {};\\n\".format(\n",
    "                    hex(current_ptr_addr), \n",
    "                    hex(potential_ptr_int)\n",
    "                )\n",
    "                \n",
    "                counter += 1\n",
    "\n",
    "        # end of graph\n",
    "        graph_file_as_string += \"}\"\n",
    "\n",
    "        if counter > 0:\n",
    "            # open .gv file\n",
    "            save_file_path = os.path.join(\n",
    "                PARAMS.TEST_DATA_DIR, \n",
    "                str(os.path.basename(raw_heap_dump_file_path)).replace('.raw', '.gv')\n",
    "            )\n",
    "\n",
    "            # save the graph file\n",
    "            with open(save_file_path, 'w') as graph_file:\n",
    "                graph_file.write(graph_file_as_string)\n",
    "\n",
    "            print(\"Writing graph to file: %s done.\" % PARAMS.TEST_DATA_DIR + PARAMS.TEST_GRAPH_DATA_FILENAME)\n",
    "            print(\"Nb of found potential pointers: %d\" % counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of files to process: 1065\n",
      "/home/onyr/Documents/code/phdtrack/phdtrack_data/Training/Training/scp/V_7_8_P1/16/32668-1644391327-heap.raw\n",
      "/home/onyr/Documents/code/phdtrack/phdtrack_data/Training/Training/scp/V_7_8_P1/16/1495-1644391327-heap.raw\n",
      "/home/onyr/Documents/code/phdtrack/phdtrack_data/Training/Training/scp/V_7_8_P1/16/31270-1644391327-heap.raw\n",
      "/home/onyr/Documents/code/phdtrack/phdtrack_data/Training/Training/scp/V_7_8_P1/16/551-1644391327-heap.raw\n"
     ]
    }
   ],
   "source": [
    "# follow the pointers and build the graphs for all files\n",
    "file_paths = glob.glob(os.path.join(PARAMS.DATA_DIR_PATH, '*.raw'), recursive=False)\n",
    "file_paths: list[str] = list(set(file_paths)) # remove duplicates\n",
    "print(\"Nb of files to process: %d\" % len(file_paths))\n",
    "\n",
    "# print first 4 file_paths\n",
    "for i in range(4):\n",
    "    print(file_paths[i])\n",
    "\n",
    "count = 0\n",
    "for file_path in file_paths:\n",
    "    follow_pointers_and_build_graph(file_path)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/onyr/Documents/code/phdtrack/phdtrack_project_3/data/graphs/graph_302-1644391327.gv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# read a .gv file and display it\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(PARAMS\u001b[39m.\u001b[39;49mTEST_DATA_DIR, PARAMS\u001b[39m.\u001b[39;49mTEST_GRAPH_DATA_FILENAME), \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     graph \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[1;32m      4\u001b[0m     graph_png_file_path \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(PARAMS\u001b[39m.\u001b[39mTEST_DATA_DIR, PARAMS\u001b[39m.\u001b[39mTEST_GRAPH_DATA_FILENAME))\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m.gv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/phdtrack/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/onyr/Documents/code/phdtrack/phdtrack_project_3/data/graphs/graph_302-1644391327.gv'"
     ]
    }
   ],
   "source": [
    "# read a .gv file and display it\n",
    "with open(os.path.join(PARAMS.TEST_DATA_DIR, PARAMS.TEST_GRAPH_DATA_FILENAME), 'r') as f:\n",
    "    graph = f.read()\n",
    "    graph_png_file_path = str(os.path.join(PARAMS.TEST_DATA_DIR, PARAMS.TEST_GRAPH_DATA_FILENAME)).replace('.gv', '.png')\n",
    "    s = Source(graph)\n",
    "    s.render(outfile=graph_png_file_path, format='png', view=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phdtrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "828c4622dac9967a1e498ff679a89b1404201a56ae91cf46826d65c256cdc648"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
